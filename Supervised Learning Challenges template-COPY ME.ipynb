{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Challenges\n",
    "\n",
    "\n",
    "Get the [congressional votes data](house-votes-84.csv) in your repo.\n",
    "\n",
    "These are votes of U.S. House of Representatives Congressmen on 16 key\n",
    "issues in 1984. You can find more information about it [here](house-votes-84-description.txt).\n",
    "\n",
    "We will try to see if we can predict the house members' party based on\n",
    "their votes.   \n",
    "We will also use some of the general machine learning tools we learned.\n",
    "\n",
    "#### Challenge 1 `[Python]`\n",
    "Load the data into a pandas dataframe. Replace `'y'`s with `1`s, `'n'`s with\n",
    "`0`s.\n",
    "\n",
    "Now, almost every representative has a `?`. This represents a no vote\n",
    "(they were absent or some other similar reason). If we dropped all the\n",
    "rows that had a `?`, we would throw out most of our data. Instead, we\n",
    "will replace `?` with the _best guess_ (in the Bayesian sense): in the\n",
    "absence of any other information, we will say that the probability of\n",
    "the representative saying YES is the ratio of others that said YES\n",
    "over the whole votes.\n",
    "\n",
    "So, convert each `?` to this probability (when yes=1 and no=0, this is\n",
    "the mean of the column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0        1    2    3         4         5    6    7    8    9    10  \\\n",
      "0  republican  0.00000  1.0  0.0  1.000000  1.000000  1.0  0.0  0.0  0.0  1.0   \n",
      "1  republican  0.00000  1.0  0.0  1.000000  1.000000  1.0  0.0  0.0  0.0  0.0   \n",
      "2    democrat  0.44208  1.0  1.0  0.417453  1.000000  1.0  0.0  0.0  0.0  0.0   \n",
      "3    democrat  0.00000  1.0  1.0  0.000000  0.504762  1.0  0.0  0.0  0.0  0.0   \n",
      "4    democrat  1.00000  1.0  1.0  0.000000  1.000000  1.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "         11        12   13   14   15        16  \n",
      "0  0.362319  1.000000  1.0  1.0  0.0  1.000000  \n",
      "1  0.000000  1.000000  1.0  1.0  0.0  0.812689  \n",
      "2  1.000000  0.000000  1.0  1.0  0.0  0.000000  \n",
      "3  1.000000  0.000000  1.0  0.0  0.0  1.000000  \n",
      "4  1.000000  0.423267  1.0  1.0  1.0  1.000000  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv(open('house-votes-84.csv', 'r'), header=None).replace(('y', 'n', '?'), value=(1, 0, None))\n",
    "m = data.mean( numeric_only=True)\n",
    "data = data.fillna(value=m)\n",
    "print data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 2 `[Modeling]`\n",
    "Split the data into a test and training set. Use this\n",
    "function:\n",
    "\n",
    "    from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swd075/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size = 0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 3 `[Modeling]`\n",
    "Using scikit.learn's KNN algorithm, train a model that predicts the\n",
    "party (republican/democrat):\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "Read the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). \n",
    "Get your X (columns of features) and Y (target column) vectors ready for fitting and evaluating. \n",
    "Initiate the model with `knn_model = KNeighborsClassifier(n_neighbors=1)` (for a k=1 KNN). \n",
    "Call `.fit(X, Y)` on the `knn_model` with the X and Y from the training set.\n",
    "\n",
    "Try it with a lot of different k values (number of neighbors), from 1\n",
    "to 20, and on the test set calculate the accuracy (number of correct\n",
    "predictions / number of all predictions) for each k\n",
    "\n",
    "You can use this to calculate accuracy:\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "Which k value gives the highest accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.93103448275862066)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from operator import itemgetter\n",
    "\n",
    "m = (0,0)\n",
    "\n",
    "for i in range(1, 21):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=i).fit(train[range(1,data.shape[1])],train[0])\n",
    "    # print data[range(1,data.shape[1])].head()\n",
    "    pred_y = knn_model.predict(test[range(1,data.shape[1])])\n",
    "    m = max(m, (i, accuracy_score(test[0], pred_y)), key=itemgetter(1))\n",
    "\n",
    "print m\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 4 `[Modeling]`\n",
    "Make a similar model but with scikit.learn's `LogisticRegression` instead. Calculate\n",
    "test accuracy. Google the documentation. The fit / predict interface is the same for all models in scikit.learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954022988506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "def logistic_model():\n",
    "    logit_model = lr()\n",
    "    logit_model = logit_model.fit(train[range(1,data.shape[1])],train[0])\n",
    "    pred_y = logit_model.predict(test[range(1,data.shape[1])])\n",
    "    return accuracy_score(test[0], pred_y)\n",
    "print logistic_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 5 `[Python]`\n",
    "Make a bar graph of democrats and republicans. How many of each are\n",
    "there?\n",
    "\n",
    "Make a very simple predictor that predicts 'democrat' for every\n",
    "incoming example.   \n",
    "(Just make a function that takes in an `X`  --an array or matrix with\n",
    "input examples--, and returns an array of the same length as `X`, where\n",
    "each value is 'democrat'. For example, if `X` is three rows, your\n",
    "function should return `['democrat','democrat','democrat']`) Make a\n",
    "`y_predicted` vector using this and measure its accuracy.\n",
    "\n",
    "Do the same with predicting 'republican' all the time and measure its\n",
    "accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEnCAYAAABWu9M0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYqlLUkEsdUkqiKUuSQWx1CWpIP8PYSCMtH87UeMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119d74850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "data[0].value_counts().plot(kind='bar')\n",
    "\n",
    "def dem_predict(df):\n",
    "    return ['democrat']*df.shape[0]\n",
    "\n",
    "def rep_predict(df):\n",
    "    return ['republican']*df.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 6 `[Visualization]`\n",
    "Plot the accuracies of each predictor as a function of k. Since k only matters for KNN,\n",
    "your logistic regression accuracy, 'democrat' predictor accuracy and\n",
    "'republican' predictor accuracy will stay the same over all k, so each\n",
    "of these three will be a horizontal line. But the KNN accuracy will\n",
    "change with k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11cccaa10>,\n",
       " <matplotlib.lines.Line2D at 0x11cccac10>,\n",
       " <matplotlib.lines.Line2D at 0x11ccd9310>,\n",
       " <matplotlib.lines.Line2D at 0x11ccd9950>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAECCAYAAAAFL5eMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c601590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def k_model(k):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k).fit(train[range(1,data.shape[1])],train[0])\n",
    "    # print data[range(1,data.shape[1])].head()\n",
    "    pred_y = knn_model.predict(test[range(1,data.shape[1])])\n",
    "    return accuracy_score(test[0], pred_y)\n",
    "\n",
    "x = range(1,21)\n",
    "dem_pred = [accuracy_score(test[0], dem_predict(test[0]))]*20\n",
    "rep_pred = [accuracy_score(test[0], rep_predict(test[0]))]*20\n",
    "knn_pred = map(k_model, x)\n",
    "log_pred = [logistic_model()]*20\n",
    "\n",
    "plt.plot(x, dem_pred, x, rep_pred, x, knn_pred, x, log_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 7 `[Modeling]`\n",
    "When you found the k value with highest test accuracy in Challenge 3, you used a single test set. \n",
    "Use scikit.learn's cross-validation tools to get a range of accuracies for each k. \n",
    "Using the average cross validation accuracy, does the best k change? \n",
    "Can you imagine cases where it might and might not change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0.93323922454357233, 0.070905489334143659)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "\n",
    "X = data[range(1,data.shape[1])]\n",
    "Y = data[0]\n",
    "def k_model_cross(k):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    # print data[range(1,data.shape[1])].head()\n",
    "    cv_values = np.array(cross_validation.cross_val_score(knn_model, X, Y, cv=20))\n",
    "    return (k, np.mean(cv_values), np.std(cv_values))\n",
    "print max(map(k_model_cross, range(1,21)), key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 8 `[Visualization]`\n",
    "Like in Challenge 6, make a graph of  accuracies for each k value. \n",
    "This time, put error bars in your graph, using your results from Challenge 7.\n",
    "Use the standard deviation of the cross validation accuracy values for each k as its error bar height (for the KNN predictor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 3 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAECCAYAAAASDQdFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGqNJREFUeJzt3XmQXOV97vHv6Z5NmumZ0dLaRrtG/ARYlpCEETKIPU4C\nsSG2b4yXe4slIcI3lSowzvWWcvkmVaQUyHqV+AKWnUR2bKBwKsQsF5tFFmYAsYP0akYCtKLRNpuW\nWbrP/aN7Rq3RMt3TLXXPvM+namq6zznv278+OvOcc95z1B2EYYiIiPghUuwCRETk3FHoi4h4RKEv\nIuIRhb6IiEcU+iIiHlHoi4h4pCybhczsEuBe59xVg6b/HvAdoBdY65x7MD19I9CeXux959xthStZ\nRESGa8jQN7N7gK8AXYOmlwH3A0uBo8AGM/sPoAPAOXd1wasVEZG8ZDO80wLcdIrp5wPNzrkO51wv\n8GtgJbAIqDazp8zsmfRZgoiIlIAhQ9859xjQd4pZtRwfwgHoBOqAw8Bq59yngFXAOjPTtQMRkRKQ\nTxh3kAr+fjGgDWgG1gE455qBA8DUPF5HREQKJKsLuWnBoOebgEYzqweOAJcDq4FbgYXAV81sGqmd\nwZ6hOg/DMAyCwS8hIiJDyCk4cwn9EMDMbgaqnXMPmtldwNPpF33IObfHzB4C1prZeiAJ3OqcSw5Z\ndRCwb19nLrXLGcTjMa3PAtG6LCytz8KKx2M5LR+U0KdshtoQCkd/WIWjdVlYWp+FFY/HcjrS1wVW\nERGPKPRFRDyi0BcR8YhCX0TEIwp9ERGPKPRFRDyi0BcR8YhCX0TEIwp9ERGPKPRFRDyi0BcR8YhC\nX0TEIwp9ERGPKPRFRDyi0BcR8YhCX0TEIwp9ERGPKPRFRDyi0BcR8YhCX0TEIwp9ERGPKPRFRDyi\n0BcR8YhCX0TEIwp9ERGPKPRFRDyi0BcR8YhCX0TEIwp9ERGPKPRFRDyi0BcR8YhCX0TEIwp9ERGP\nKPRFRDyi0BcR8YhCX0TEI6Mm9O9Z8yL3rHmx2GXkTe9DzobR9O8xWt5Lsd5HWTYLmdklwL3OuasG\nTf894DtAL7DWOfegmQXAGmARcAy43Tm3rbBli/ilPxxW37miyJXk5541LxKNBtx7x6VFrQFG/roc\nriGP9M3sHuABoHLQ9DLgfuBa4Ergj8wsDtwIVDrnVgDfSC/jhdFyBCJyKtq+jyuVdTGcGrIZ3mkB\nbjrF9POBZudch3OuF1gPXAFcBjwJ4JxrApblXJXk5Z41L3LbXzxd7DJEpAQNGfrOuceAvlPMqgXa\nM553AXVAbND0PjMbNdcO5NwplaOpfI2W9yGjQ1Zj+qfRQSr4+8WAQ+npsYzpEedcMpsO4/HY0Aud\nRjQa5N1HvgpRQyn00X+W8NC3f6toNRSqj0Ip9vvIt49SqKFU+iiFGgrdRy5yCf3BvW8CGs2sHjgC\nXA6sTs+7AXjEzJYDb2f7Avv2deZQzokSiTDvPvJViBoK1Uc0Ggy7j1J6H/n2UQjxeKzo7yPfPkqh\nhv4+8tk2C1FHKa2LQvWRi1xCPwQws5uB6vSdOncBT5PaITzknNtjZo8B15nZhnS7W3KuSkREzoqs\nQt859yGwIv34JxnT/wv4r0HLhsCqAtZ4Tvh+G5eI+CGfMX2RklaIHXkp3FcuUki6q0ZExCMKfRER\njyj0RUQ8otAXEfGIQl9ExCMKfRERjyj0RUQ8otAXEfGIQl9ExCMKfRERjyj0RUQ8otAXEfGIQl9E\nxCMKfRERjyj0RUQ8otAXEfGIQl9ExCMKfRERjyj0RUQ8otAXEfGIQl9ExCMKfRERjyj0RUQ8otAX\nEfGIQl9ExCMKfRERjyj0RUQ8otAXEfGIQl9ExCMKfRERjyj0RUQ8otAXEfGIQl9ExCMKfRERjyj0\nRUQ8UjbUAmYWAGuARcAx4Hbn3LaM+V8Bvga0AT9yzv0gPX0j0J5e7H3n3G0Frl1ERHI0ZOgDNwKV\nzrkVZnYJcH96GmY2AfgesBjoAJ4xs2eAvQDOuavPStUiIjIs2QzvXAY8CeCcawKWZcybC7zhnGt3\nzoXAK8ByUmcF1Wb2lJk9k95ZiIhIkWUT+rUcH6YB6DOz/nbNwIVmFjezscA1QDVwGFjtnPsUsApY\nl9FGRESKJJsg7gBimW2cc0kA51wbcBfwKLAO2AjsJ7UzWJdephk4AEwtXNkiIjIc2YzpbwBuAB4x\ns+XA2/0zzCwKLHHOrTSzCuBp4JvArcBC4KtmNo3UTmPPUC8Uj8eGWuS0otEgrz7ybT+a+iiFGgrR\nRynUUCp9lEINpdJHKdRQ6D5ykU3oPwZcZ2Yb0s9vMbObgWrn3INmhpm9BhwF7nPOHTSzh4C1ZrYe\nSAK39p8dnMm+fZ05v4F+iUSYVx/5ti+1PqLRwPt1UQrrspB15NNHKdTQ30ex12cprYtC9ZGLIUM/\nfYF21aDJWzLmf4/UHTyZbXqBL+dcjYiInFW6uCoi4hGFvoiIRxT6IiIeUeiLiHhEoS8i4hGFvoiI\nRxT6IiIeUeiLiHhEoS8i4hGFvoiIRxT6BRKG4cBPMsz98zBERM6FbD5wbdRLhiHdvQl6ehP8/SNv\nkUiG9CWSJBLJ9OOQvmSSRCI9PRmSSCRPmJ5IHg/62//qWQIgEgmIRoKB35mPI5GASCRy0vT2w92U\nl0Xp6U1QUR4t3krxSBiGdB7t5WDHMQ60d3Ow81jqcUc37Ye7AfjFSx/yifMnMbFuTJGrFcmP16Ef\nhiFvbT3Ao89vo+toLwBvtOw/YZmyaEA0GqEskv4dDSiLBlRVlBONRIimn5dFImzb3QHAvIZaksmQ\nRBimfqd/khm/+xIhyd6+k+b1JUL6En18+8Em/ttVjSy1OEGQ+8enynHdPQkOdh7jQMcxDnZ0pwP9\n+OODnd309p35Q2AfeW4rjzy3lcaGOi65YDLLFkyirrriHL0DyRTqTDov3ob+lh1tPPr8Vpp3thMA\nleURxlSU8Rd/uHwgyCNBkFPg3rPmRQC+/sUlw67r7v+zgaPdfRzq7GbNz99hwcx6br72PGZMqhl2\nn6UqDEMOH0u910Od3bR1ddPW2c2hruPPAb71wEuEIYSpRunH6d+pifSfaIUD86HzSA+EsOr+509b\nQ2xsOdMmVjOhtorxsUrG11Yxoe7447/8l1eJRAKuv3QWTe/txW1vo2VXOz9+ZgsXzBrHJy6YzNLz\nJjG2qrB/Solkkp2th9mys42Wne0c6uomGgn4zTsfsXj+RMZU+vGnG4YhHx08QvPOdprT6+JgZzdB\nAH/38JvMn1FPY0Mdc6bGKC/TmXE2/NhyMuxo7eLR57fy1tYDAFw0fyI3rZzL3z38FkDB/3hzFQkC\nqqvKufsLi/npL5t5c+sBvrv2Za5c3MCNl88hNnZkHF32X9vYsqONtnSIDw72tq6eIY+wgwC6jvYS\npJ8EAQRAMOhxNEgtGwSRgWUPH+2FABbMrE+FeW0V42urGF9byYTaKsbFKoccQguC1NDbFYsbuGJx\nA4c6u3l1cytNm/by7geHePeDQ/zrU46Fcyew/MIpLJo3YVjDcke7+9i2u4PmnW0072xn2+4OunsT\nx+sAepMhDzz+HmXRCAvnjufi8yexaN7o2gH09iX44KNOmne207KznZZd7QNn4QBjKssoi0ZIJkPe\n3HqAN9N/x2XRgNlTammcXsf86XU0NtSNmL+Vc230bC1DaG07ys/Xb6Pp3b2EgM2o53NXzmNeQ12x\nSzulKePH8qefX8Tb2w7w779s5tnXd9H03l4+c/kcrrqogbJoca/B94+D72s7mv45xr62o+xPPz/Y\nmTpKv3fdaye1DYDamgqmTaxmXE0l42KV1McqBz2u4M8fepkgCFh954ph1dh/5nX3Fy4a9vscbFys\nkusunsF1F8+gte0oL7+3l6ZNe3m9eT+vN++nsiLKkvkTueSCyVwwe/xp/50OdhwbCLbmXW3saO0i\nc9Ri6oSxzJ9enwqw6XWs/vHrJJMhVy5p4JXNrQOvV14W4eNzJwzsACorRtbRbueRHlp2pdfDznY+\n+KiDvowvBplYV8XH5o5nfkMd86fXMy1ezZ/9028A+OZXltKyq53mHW0070rtKFt2tfNkU6rtlPFj\nB9bf/On1TB43RkOleBD6bV3d/OeLH/DCG7tJJENmTq7hc1fM48I540fEBrBw7gTOnzWOX722i//4\n9fv85Jlmnn9jNzdfM58L54w/q6/d25dgf/uxgUA/IeDbj9LdkzipTQDUxypTw2ORgGuWTj8p2Otq\nKohGht5plfq/z6T6MdywYjY3rJjNztYumjbtpem9vfzm3dRPzZhyllmc3r4kQQC/em1nOujbONDR\nPdBPWTRCY8PxcGpsqKNmTPkJrxUEAdFowKc/OYdPf3IOu/Z18crmVl7Z3MrGLfvYuGUfFWURPt44\nkU8smMTCeROoPMs3AvSfzWVet+q/PnXC9auMab19SXr6Qtb+YhMtu9rZc+BIxnuEmZNiJwT1uFjl\naV9/XKySixdM4uIFkwA41pM6W0rtSNvZuqud9W/tYf1bqW9qjY0tp7GhjqPdfZRFI/QlkkU/eCqG\nURv6R4718kTTdv7fqzvo6U0yedwYblo5l2ULJhEp8TAZrCwa4bcunsHyCyfz2AvbeOGN3dz30zdY\n3DiRP7imkcnjxub9Gt29CT7YkzpS6jjSQyKR5I//+nlOdcmssiJKvG4M8foq4vVjMn6qmFhXRXlZ\ndOAo+/NXNuZd20gwfVIN0yfV8Psr57JtdwdNm/byyqZWnntj98Ay//Z06gvnasaUc9H8ialga6hn\n1pQY5WW5hU9DvIaGeA2fuWwOu/Yf5uVNrbyyaS+vbm7l1c2tVJZHWdQ4gYsXTGbh3KEPDpJhSNeR\n3tTwW1cP7V3pobjDPbR1dtN+uIdDncdIhnDHXz9HIpHfrcnr39pDZUWUC2ePozF9RjN3Wi1VFcOP\npKqKMi6YPZ4LZqfebzIZsnNfV2pHuyt1TeD15uM3avzJ366nsaEWmzkOm1nPnKm1XuwERl3od/cm\n+OXGnTzx0occPtZHfU0FX7hmDpctnDri/0Frx1bwP357AVdd1MCPn2nmjZb9vPP+Aa67eAY3XDo7\n67HdMAw52NFNS/poqGVXOztau0647TQSgM2sZ2JGoPeHe2xMeckfhRdLEATMa6hjXkMdX7h6Pm77\nIf7+0bcB+OK182mcXseU8WMLtv6CIGB6vIbp8RpuunwOO1rTZwCbWnk5/VNZESVMhlSUR3nhzd20\ndXXT3tUzEPBtXd10HO454d9/sGgkGPg9Y1JN6hbj4PS3I6emRU6a9sKbuymLRrj7DxYzfVJ1Vmd8\nwxWJBMycHGPm5BjXLJ0OpIbVvrv2FXr7kkysqxq4LgNQURZhXkMdC2bWYzPHMWdqbc4745Fg1IR+\nmL7X/n99/ze0d/VQXVXG56+axzVLpo+6+91nTo7xZ1+8iFc2t/KzZ1t44qXtvPj2R3z2inmsWDjl\npOX7Ekm27+1KjZ2mg/5QZ+bwQsDsqTEaG+qYN62OnzzTTCQS5HUXkqRC5/zZ4weGai5fNO2svl4Q\nHA+53185l+17u3h5c+qMY3/7MXr6kvzwic0ntCmLBtTXVDJ7aoz6mkrqqyupj1VQl/6del5JdVUZ\nX0+PpX/7vy8bdo0b3T6i0YBZU2J5vdfhGl9bRWV5lMryKP/79kvoONzDlh1tuO1tbN5xiE0fpn7g\nfcrLIsybVsuC9JnA3Gm1o+IOoVER+u2He2g73EMyGVJRHuH6S2fxO5fMZGxV+dCNR6ggCPjE+ZNZ\n1DiRp5q284uXPuQHv9jEs6/vpLcvQV8i4OFnW2jZ1c4HH3WecJdMbXUFS86Lp8aRG+qYNaXmhI35\np79qKcZbkgIKglSwzpoS43NXzOOuf9xAb1+Sm6+dT11NRSrga1Jh7vNZW211BcsWTGJZ+rpA55HU\nTmDz9vSOIP0DqWHWedNqsZn19PYliEYiHDnWe6buz6h/eCyfPobzfxZGReh39yYghMryKPfesZy6\nmtNf/BltKsujfPqyOXxy4VQefq6Flze1Dsx7omk7QQAz4jXMm15H47Q65k2vI15X5fUfum+CIKAs\nGqEsGuGTC6cWu5ySFhtbwVKbxFJL7QS6jvamdwKHcNvbUmcFO9oGlv+ff7s+79csRB+5GBWhP6l+\nzMBVfp8CP9OEuir++DMf4+olbfzNz96kLBqw6saPMWdq7ai6j1vkXKoZU86S8+IsOS8OpHYCzTva\neODx90gkQz6Wxx1077x/ECCvPt5N95ELpcEoc96MemrGlBONBgN3MYhIYdSMKeei8+JUp4eO/+Sz\nHx92X/13uBWij1yMvkvTIiJyWgp9ERGPKPRFRDyi0BcR8YhCX0TEIwp9ERGPKPRFRDyi0BcR8YhC\nX0TEIwp9ERGPKPRFRDyi0BcR8YhCX0TEI0N+yqaZBcAaYBFwDLjdObctY/5XgK8BbcCPnHM/GKqN\niIgURzZH+jcClc65FcA3gPv7Z5jZBOB7wErgSuBLZjbzTG1ERKR4sgn9y4AnAZxzTUDmF2TOBd5w\nzrU750LgFeDSIdqIiEiRZBP6tUB7xvM+M+tv1wxcaGZxMxsLXAOMHaKNiIgUSTZB3AFkfnV9xDmX\nBHDOtQF3AY8C64CNwH5SgX/KNiIiUjzZfF3iBuAG4BEzWw683T/DzKLAEufcSjOrAJ4GvgmUn67N\nmcTjsaEXOo1oNMirj3zbj6Y+SqGGQvRRCjWUSh+lUEOp9FEKNRS6j1xkE/qPAdeZ2Yb081vM7Gag\n2jn3oJlhZq8BR4H7nHMHzeykNtkUs29fZ671D0gkwrz6yLd9qfURjQber4tSWJeFrCOfPkqhhv4+\nir0+S2ldFKqPXAwZ+ukLtKsGTd6SMf97pO7gGaqNiIgUmS6uioh4RKEvIuIRhb6IiEcU+iIiHlHo\ni4h4RKEvIuIRhb6IiEcU+iIiHlHoi4h4RKEvIuIRhb6IiEcU+iIiHlHoi4h4RKEvIuIRhb6IiEcU\n+iIiHlHoi4h4RKEvIuIRhb6IiEcU+iIiHlHoi4h4RKEvIuIRhb6IiEfKil2ASClbfecK4vEY+/Z1\nFrsUkYJQ6KetvnNFsUsQETnrNLwjIuIRHenLqKWzN5GT6UhfRMQjCn0REY8o9EVEPKIx/QLSGLKI\nlDod6YuIeERH+lKydOYkUngK/RKjoBORs0nDOyIiHtGRvsgIoDNAKRSFvoiMKNoB5mfI0DezAFgD\nLAKOAbc757ZlzP8ScBfQB6x1zv1zevpGoD292PvOudsKXLuIiOQomyP9G4FK59wKM7sEuD89rd9q\n4HzgCPCemf2E1M4B59zVBa5XRETykE3oXwY8CeCcazKzZYPmvwmMA8L085DUWUG1mT0FRIFvOeea\nClOynG06fS4srU8pJdncvVPL8WEagD4zy2z3LrAReBt43DnXQeqof7Vz7lPAKmDdoDYyyq2+c4XC\nTqQEZXOk3wHEMp5HnHNJADNbCFwPzAIOkwr3zwL/CbQAOOeazewAMBXYdaYXisdjZ5p9RtFokHcf\no4XWReGN9HVZiG2iVPrIV6m8j0L2kYtsQn8DcAPwiJktJ3VE36+d1FF9t3MuNLNWUkM9twILga+a\n2TRSO409Q71QPl9Jl0iEefcxWiQSIdFooHVRIKPh6xIL8fdx7x2X5t1HKWybhVgXpdZHLrIJ/ceA\n68xsQ/r5LWZ2M1DtnHvQzP4v8Gsz6wa2Aj8EAmCtma0HksCt/WcHIuKvUvjOYd+HHYcMfedcSGpc\nPtOWjPnfB75/iqZfzq80EREpNF1cFRHxiEJfRMQjCn0REY/os3dEPOD7xUs5TqE/CpXCHRIiUppG\nTejrSEZEzpVSyZvh1KExfRERj4yaI30RkZGkWGcLOtIXEfGIQl9ExCMKfRERjyj0RUQ8otAXEfGI\nQl9ExCMKfRERjyj0RUQ8otAXEfGIQl9ExCMKfRERjyj0RUQ8otAXEfGIQl9ExCMKfRERjyj0RUQ8\notAXEfGIQl9ExCMKfRERjyj0RUQ8otAXEfGIQl9ExCMKfRERjyj0RUQ8otAXEfGIQl9ExCMKfRER\njyj0RUQ8UjbUAmYWAGuARcAx4Hbn3LaM+V8C7gL6gLXOuX8eqo2IiBRHNkf6NwKVzrkVwDeA+wfN\nXw1cDVwG3G1mdVm0ERGRIsgm9C8DngRwzjUBywbNfxMYB4xJPw+zaCMiIkWQTejXAu0Zz/vMLLPd\nu8BG4G3gcedcRxZtRESkCLIJ4g4gltnGOZcEMLOFwPXALGA2MNnMPkcq8E/ZRkREimfIC7nABuAG\n4BEzW07qiL5fO3AE6HbOhWbWCtSn23z6NG1OJ4jHY0MvJVnT+iwcrcvC0vosniAMwzMukHEnzsfT\nk24BlgLVzrkHzewO4FagG9gK/CGQGNzGObel8OWLiEguhgx9EREZPXRxVUTEIwp9ERGPKPRFRDyi\n0BcR8Ug2t2yeNfqMnsIzs40c/49x7zvnbitmPSOVmV0C3Oucu8rM5gE/BJLAO865rxa1uBFm0Lpc\nDDwO9N/N90/OuYeLV93IYWZlwA9I/Z+oCuAvgffIcdss9pG+PqOngMysEsA5d3X6R4E/DGZ2D/AA\nUJmedD/wTefcFUDEzD5TtOJGmFOsy6XAfRnbqAI/e18G9jvnVgK/Dfwjw9g2ix36+oyewloEVJvZ\nU2b2TPoIS3LXAtyU8Xypc259+vETwLXnvqQR66R1CVxvZs+b2YNmVl2kukainwHfST+Okvpk4yW5\nbpvFDn19Rk9hHQFWO+c+BawC1ml95s459xipP6h+QcbjTqDu3FY0cp1iXTYB96SPTLcB3y1GXSOR\nc+6Ic+6wmcWAh4FvMYxts9iBcNrP9ZFh2QKsA3DONQMHgKlFrWh0yNwmY0BbsQoZBX7unHs9/fgx\nYHExixlpzGwG8CvgR865f2cY22axQ38D8LsAOXxGj5zercB9AGY2jdRGsKeoFY0Or5nZyvTj3wHW\nn2lhOaOnzKx/GPcaUp/QK1kws8nAU8DXnXM/Sk9+Pddts6h375Da019nZhvSz28pZjGjwEPAWjNb\nT+oI4FadORXE14AHzKwc2AQ8UuR6RrJVwD+YWQ/wEfBHRa5nJPkGqQ+0/I6Z/Tmp7y75U1LrM+tt\nU5+9IyLikWIP74iIyDmk0BcR8YhCX0TEIwp9ERGPKPRFRDyi0BcR8YhCX0TEIwp9ERGP/H95TzWf\nd+aFRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c435510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "means = map(itemgetter(1), map(k_model_cross, range(1,21)))\n",
    "stds = map(itemgetter(2), map(k_model_cross, range(1,21)))\n",
    "plt.figure()\n",
    "plt.errorbar(range(1,21), means, yerr=stds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 9 `[Modeling]`\n",
    "Calculate the accuracy, precision, recall and f1 scores on the test set for each classifier you built (including the trivial ones).\n",
    "(Use only one KNN with the best k, no need to do this for all k values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': array([ 0.92035398,  0.93442623]), 'f1': array([ 0.94117647,  0.8976378 ]), 'precision': array([ 0.96296296,  0.86363636]), 'accuracy': 0.92528735632183912}\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "def k_model_all(train_set, test_set, k):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k).fit(train_set[range(1,train_set.shape[1])],train_set[0])\n",
    "    pred_y = knn_model.predict(test_set[range(1,test_set.shape[1])])\n",
    "    f1 = sklearn.metrics.f1_score(test_set[0], pred_y, average=None, labels=['democrat', 'republican'], pos_label=None)\n",
    "    ps = sklearn.metrics.precision_score(test_set[0], pred_y, average=None, labels=['democrat', 'republican'], pos_label=None)\n",
    "    rs = sklearn.metrics.recall_score(test_set[0], pred_y, average=None, labels=['democrat', 'republican'], pos_label=None)\n",
    "    acc_s = sklearn.metrics.accuracy_score(test_set[0], pred_y)\n",
    "    return {'f1':f1, 'precision': ps, 'accuracy': acc_s, 'recall': rs}\n",
    "\n",
    "print k_model_all(train, test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 10 `[Modeling]`\n",
    "Calculate the same metrics as in Challenge 9, but use cross validation instead of that test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': array([ 0.93258427,  0.93452381]), 'f1': array([ 0.94497154,  0.9154519 ]), 'precision': array([ 0.95769231,  0.89714286]), 'accuracy': 0.93333333333333335}\n"
     ]
    }
   ],
   "source": [
    "def k_model_all_cross(train_set, k):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    pred_y = cross_validation.cross_val_predict(knn_model, train_set[range(1,train_set.shape[1])], train_set[0], cv=20)\n",
    "    f1 = sklearn.metrics.f1_score(train_set[0], pred_y, average=None, labels=['democrat', 'republican'], pos_label=None)\n",
    "    ps = sklearn.metrics.precision_score(train_set[0], pred_y, average=None, labels=['democrat', 'republican'], pos_label=None)\n",
    "    rs = sklearn.metrics.recall_score(train_set[0], pred_y, average=None, labels=['democrat', 'republican'], pos_label=None)\n",
    "    acc_s = sklearn.metrics.accuracy_score(train_set[0], pred_y)\n",
    "    return {'f1':f1, 'precision': ps, 'accuracy': acc_s, 'recall': rs}\n",
    "print k_model_all_cross(data, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 11a `[Python]`\n",
    "A Portuguese bank is having a telemrketing campaign. They try to get their clients to subscribe to a term deposit product. Often more than one call to the same client is required. They have been recording their success or failure with each client, along with all the data they have on that client. To cut costs, the bank wants to predict who is likely to subscribe, so they can call those clients and not waste time and money calling people that likely won't subscribe anyway. To that end, look in the repo directory.  The records are in *challenges/challenge_2/bank/bank.csv* and the columns are described in *challenges/challenge_2/bank/bank-description.md*\n",
    "\n",
    "Build a  classifier with all the numeric features. Calculate the accuracy, precision, and recall for identifying the subscribers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   balance       pdays  housing  age  y  poutcome_success  poutcome_failure  \\\n",
      "0     2143  224.577692        1   58  0               0.0               0.0   \n",
      "1       29  224.577692        1   44  0               0.0               0.0   \n",
      "2        2  224.577692        1   33  0               0.0               0.0   \n",
      "3     1506  224.577692        1   47  0               0.0               0.0   \n",
      "4        1  224.577692        0   33  0               0.0               0.0   \n",
      "\n",
      "  new_call  \n",
      "0     True  \n",
      "1     True  \n",
      "2     True  \n",
      "3     True  \n",
      "4     True  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-eca6d9a24578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelling_bank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-eca6d9a24578>\u001b[0m in \u001b[0;36mmodelling_bank\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#         y_score = model[1].decision_function(test_set[cols]).ravel()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mlogit_roc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# def convert_to_categories(df, columns):\n",
    "#     les = {}\n",
    "#     for column in columns:\n",
    "#         le = preprocessing.LabelEncoder()\n",
    "#         df[column] = le.fit_transform(df[column])\n",
    "#         les[column] = le\n",
    "#     return (df, les)\n",
    "    \n",
    "\n",
    "def decode_categories(df, columns, les):\n",
    "    for column in columns:\n",
    "        df[column] = les[column].inverse_transform(df[column])\n",
    "    return df\n",
    "\n",
    "def modelling_bank(df):\n",
    "    train_set, test_set = train_test_split(df.dropna(how='any'), test_size = 0.4, random_state=3)\n",
    "    cols = [col for col in df.columns if col not in ['y']]\n",
    "    models = [('LinearSVC', LinearSVC()), ('logistic', LogisticRegression()), ('mlp', MLPClassifier(algorithm='l-bfgs', alpha=1e-2, learning_rate='adaptive', hidden_layer_sizes=(5, 2), random_state=1, activation='logistic'))]\n",
    "    results = []\n",
    "    for model in models:\n",
    "        model[1].fit(train_set[cols],train_set['y'])\n",
    "        pred_y = model[1].predict(test_set[cols])\n",
    "#         y_score = model[1].decision_function(test_set[cols]).ravel()\n",
    "        probs = model[1].predict_proba(test_set[cols])\n",
    "        logit_roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, probs[:,1])\n",
    "        #roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        ##############################################################################\n",
    "        # Plot of a ROC curve for a specific class\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % logit_roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic example')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        f1 = sklearn.metrics.f1_score(test_set['y'], pred_y, average=None)\n",
    "        ps = sklearn.metrics.precision_score(test_set['y'], pred_y, average=None)\n",
    "        rs = sklearn.metrics.recall_score(test_set['y'], pred_y, average=None)\n",
    "        acc_s = sklearn.metrics.accuracy_score(test_set['y'], pred_y)\n",
    "        conf_m = sklearn.metrics.confusion_matrix(test_set['y'], pred_y, labels=[0,1])\n",
    "        results.append({'type':model[0], 'f1':f1, 'precision': ps, 'accuracy': acc_s, 'recall': rs, 'matrix':conf_m})\n",
    "    return results\n",
    "\n",
    "\n",
    "df = pd.read_csv(open('../project_2/data/bank/bank.csv', 'r'), delimiter=';').replace(('yes','no', 'unknown'), (1, 0, None))\n",
    "bank_data = df[['balance', 'pdays', 'housing', 'age', 'y']]\n",
    "cat_dummies = pd.get_dummies(df['poutcome'].fillna('other'), dummy_na=False, prefix='poutcome')[['poutcome_success', 'poutcome_failure']]\n",
    "new_data = pd.concat([bank_data, cat_dummies], axis=1, join='inner')\n",
    "mean = np.mean(new_data['pdays'].replace((-1,),(None,)).dropna())\n",
    "new_data['new_call'] = bank_data['pdays'].apply(lambda x: x<0)\n",
    "new_data['pdays'] = new_data['pdays'].apply(lambda x: (x if x>=0 else mean))\n",
    "print new_data.head()\n",
    "\n",
    "m = modelling_bank(new_data)\n",
    "print m\n",
    "\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# cols = [col for col in new_data.columns if col not in ['y']]\n",
    "# x_scaled = min_max_scaler.fit_transform(new_data[cols])\n",
    "# df_normalized = pd.DataFrame(x_scaled)\n",
    "# df_normalized.columns = cols\n",
    "# df_normalized['y'] = new_data['y']\n",
    "# cluster_model = DBSCAN()\n",
    "# # train_set, test_set = train_test_split(df_normalized.dropna(how='any'), test_size = 0.4, random_state=3)\n",
    "# cluster_model.fit(train_set[cols],train_set['y'])\n",
    "# pred_y = cluster_model.fit_predict(test_set[cols])\n",
    "# print set(pred_y)\n",
    "\n",
    "# print df_normalized.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 7963, 2: 6833, 1: 1403, 5: 550, 3: 478, 4: 414, 6: 251, 7: 192, -1: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print Counter(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 11b `[Modeling]`\n",
    "Is this a good predictor? Which features are contributing the most? Check if any single feature that you included in your model might be driving the classifier. If so, why? Can you use this model successfully? Can you use a model with just that column? Is something wrong? (Hint: You should not use one of the columns, but it is not obvious at initial look. Find out which one and why that might be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The rest is completely optional specialization challenges. Select the ones you're excited about, or explore other things you got curious about through the first 11-ish challenges._\n",
    "\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "\n",
    "#### Extra `[Python]` & `[Modeling]` Challenge A\n",
    "\n",
    "Instead of 'democrat' or 'republican', can you predict the vote of a\n",
    "representative based on their other votes?\n",
    "\n",
    "Reload the data from scratch. Convert y-->1, n-->0.\n",
    "\n",
    "Choose one vote. Build a classifier (logistic regression or KNN), that\n",
    "uses the other votes (do not use the party as a feature) to predict if\n",
    "the vote will be 1 or 0.\n",
    "\n",
    "Convert each ? to the mode of the column (if a senator has not voted,\n",
    "make their vote 1 if most others voted 1, make it 0 if most others\n",
    "voted 0).\n",
    "\n",
    "Calculate the cross validation accuracy of your classifier for\n",
    "predicting how each representative will vote on the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra `[Modeling]` Challenge B\n",
    "\n",
    "Back to your movie data! Choose one categoric feature to predict. \n",
    "We mention MPAA Rating in the slides, but genre, month, etc. are all decent choices. If\n",
    "you don't have any non-numeric features, you can make two bins out of\n",
    "a numeric one (like \"Runtime>100 mins\" and \"Runtime<=100 mins\")\n",
    "\n",
    "Make a bar graph of how many of each movie there is in the data. For\n",
    "example, with Ratings, show how many G, PG, PG-13, R movies there are,\n",
    "etc. (basically a histogram of your labels).\n",
    "\n",
    "Predict your outcome variable (target/labels) using KNN and logistic\n",
    "regression. Calculate their accuracies.\n",
    "\n",
    "Make a baseline stupid predictor that always predicts the label that\n",
    "is present the most in the data. Calculate its accuracy on a test set.\n",
    "\n",
    "How much better do KNN and logistic regression do versus the baseline?\n",
    "\n",
    "What are the coefficients of logistic regression? Which features\n",
    "affect the outcome how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra`[Modeling]` Challenge C\n",
    "\n",
    "This is a preview of many other classification algorithms. Scikit.learn has the same interface for all of these, so you\n",
    "can use them exactly the same way as you did `LogisticRegression` and\n",
    "`KNeighborsClassifier`. Use each of these to classify your data and\n",
    "print the test accuracy of each:\n",
    "\n",
    "Gaussian Naive Bayes\n",
    "\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "SVM (Support Vector Machine) Classifier\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "Decision Tree\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "Random Forest\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra `[Python]` Challenge D\n",
    "\n",
    "The representative votes dataset\n",
    "only had 0s and 1s. Let's just swiftly tackle the breast cancer\n",
    "surgery data we talked about in class.\n",
    "\n",
    "The data is [in the repository](haberman.csv). You can learn more about it [here](https://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival).\n",
    "\n",
    "- What is the average and standard deviation of the age of all of the\n",
    "patients?\n",
    "- What is the average and standard deviation of the age of those\n",
    "patients that survived 5 or more years after surgery?\n",
    "- What is the average and standard deviation of the age of those\n",
    "patients who survived fewer than 5 years after surgery?\n",
    "- Plot a histogram of the ages side by side with a histogram of the\n",
    "number of axillary nodes.\n",
    "- What is the earliest year of surgery in this dataset?\n",
    "- What is the most recent year of surgery?\n",
    "- Use logistic regression to predict survival after 5 years. How well\n",
    "does your model do?\n",
    "- What are the coefficients of logistic regression? Which features\n",
    "affect the outcome how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra `[Modeling]` & `[Visualization]` Challenge E\n",
    "For each representatives classifier (KNN and logistic regression), draw the ROC curve and calculate the AUC.\n",
    "As a `[Visualitation]` track bonus, make the ROC curve look good, following good data visualization principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
